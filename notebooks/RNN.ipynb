{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Notebook\n",
    "\n",
    "Notebook made for the RNN part of the assignment. Will contain all preprocessing and such, as well as implementation.\n",
    "\n",
    "This is a placeholder cell, code will follow later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries to work with\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gensim as gns\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For the sake of Preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Word Embedding\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Version: 1.26.4\n",
      "Polars Version: 1.16.0\n",
      "MatPlotLib Version: 3.9.3\n",
      "Seaborn Version: 0.13.2\n",
      "PyTorch Version: 2.5.1+cpu\n",
      "NLTK Version: 3.9.1\n",
      "SpaCy Version: 3.8.2\n",
      "Gensim Version: 4.3.3\n",
      "SciPy Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Display the libraries' versions used in this notebook\n",
    "version_list = {\"NumPy Version:\": np.__version__,\n",
    "                \"Polars Version:\": pl.__version__,\n",
    "                \"MatPlotLib Version:\": mpl.__version__,\n",
    "                \"Seaborn Version:\": sns.__version__,\n",
    "                \"PyTorch Version:\": torch.__version__,\n",
    "                \"NLTK Version:\": nltk.__version__,\n",
    "                \"SpaCy Version:\": spacy.__version__,\n",
    "                \"Gensim Version:\": gns.__version__,\n",
    "                \"SciPy Version:\": sci.__version__}\n",
    "\n",
    "for (k, v) in version_list.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining path to install NLTK libraries in\n",
    "NLTK_LIB_PATH = os.path.join(\"..\", \"venv_nlp\", \"Lib\", \"nltk_data\")\n",
    "\n",
    "# Defining download function\n",
    "def download_libs():\n",
    "    libraries = {\n",
    "        \"corpora\\\\stopwords\": \"stopwords\",\n",
    "        \"corpora\\\\wordnet\": \"wordnet\"\n",
    "    }\n",
    "\n",
    "    for resource, package in libraries.items():\n",
    "        try:\n",
    "            nltk.data.find(resource)\n",
    "            print(f\"{package.capitalize()} data exists.\")\n",
    "        except LookupError:\n",
    "            print(f\"Downloading {package}...\")\n",
    "\n",
    "            # Handle potential corrupted files\n",
    "            resource_path = os.path.join(NLTK_LIB_PATH, *resource.split('\\\\'))\n",
    "            if os.path.exists(resource_path):\n",
    "                print(f\"Removing corrupted file: {resource_path}\")\n",
    "                try:\n",
    "                    shutil.rmtree(resource_path) if os.path.isdir(resource_path) else os.remove(resource_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing corrupted file {resource_path}: {e}\")\n",
    "            # Attempt download again\n",
    "            nltk.download(package, download_dir=NLTK_LIB_PATH)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error checking {package}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NLTK data directory: ..\\venv_nlp\\Lib\\nltk_data\n",
      "Stopwords data exists.\n",
      "Wordnet data exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs(NLTK_LIB_PATH, exist_ok=True)\n",
    "    print(f\"Using NLTK data directory: {NLTK_LIB_PATH}\")\n",
    "    download_libs()\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to create or write to directory '{NLTK_LIB_PATH}'\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pl.read_csv(\"../data/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>sentiment</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;One of the other reviewers has…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;A wonderful little production.…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;I thought this was a wonderful…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;Basically there&#x27;s a family whe…</td><td>&quot;negative&quot;</td></tr><tr><td>&quot;Petter Mattei&#x27;s &quot;Love in the T…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;Probably my all-time favorite …</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;I sure would like to see a res…</td><td>&quot;positive&quot;</td></tr><tr><td>&quot;This show was an amazing, fres…</td><td>&quot;negative&quot;</td></tr><tr><td>&quot;Encouraged by the positive com…</td><td>&quot;negative&quot;</td></tr><tr><td>&quot;If you like original gut wrenc…</td><td>&quot;positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ review                          ┆ sentiment │\n",
       "│ ---                             ┆ ---       │\n",
       "│ str                             ┆ str       │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ One of the other reviewers has… ┆ positive  │\n",
       "│ A wonderful little production.… ┆ positive  │\n",
       "│ I thought this was a wonderful… ┆ positive  │\n",
       "│ Basically there's a family whe… ┆ negative  │\n",
       "│ Petter Mattei's \"Love in the T… ┆ positive  │\n",
       "│ Probably my all-time favorite … ┆ positive  │\n",
       "│ I sure would like to see a res… ┆ positive  │\n",
       "│ This show was an amazing, fres… ┆ negative  │\n",
       "│ Encouraged by the positive com… ┆ negative  │\n",
       "│ If you like original gut wrenc… ┆ positive  │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>review</th><th>sentiment</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>&quot;50000&quot;</td><td>&quot;50000&quot;</td></tr><tr><td>&quot;null_count&quot;</td><td>&quot;0&quot;</td><td>&quot;0&quot;</td></tr><tr><td>&quot;mean&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;std&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;min&quot;</td><td>&quot;\b\b\b\bA Turkish Bath sequence in…</td><td>&quot;negative&quot;</td></tr><tr><td>&quot;25%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;50%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;75%&quot;</td><td>null</td><td>null</td></tr><tr><td>&quot;max&quot;</td><td>&quot;ý thýnk uzak ýs the one of the…</td><td>&quot;positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 3)\n",
       "┌────────────┬─────────────────────────────────┬───────────┐\n",
       "│ statistic  ┆ review                          ┆ sentiment │\n",
       "│ ---        ┆ ---                             ┆ ---       │\n",
       "│ str        ┆ str                             ┆ str       │\n",
       "╞════════════╪═════════════════════════════════╪═══════════╡\n",
       "│ count      ┆ 50000                           ┆ 50000     │\n",
       "│ null_count ┆ 0                               ┆ 0         │\n",
       "│ mean       ┆ null                            ┆ null      │\n",
       "│ std        ┆ null                            ┆ null      │\n",
       "│ min        ┆ \b\b\b\bA Turkish Bath sequence in… ┆ negative  │\n",
       "│ 25%        ┆ null                            ┆ null      │\n",
       "│ 50%        ┆ null                            ┆ null      │\n",
       "│ 75%        ┆ null                            ┆ null      │\n",
       "│ max        ┆ ý thýnk uzak ýs the one of the… ┆ positive  │\n",
       "└────────────┴─────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a stopword set\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\"im\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a regex function to remove special characters, links, etc.\n",
    "def regex_cleanse(text: str):\n",
    "    # URLS\n",
    "    text = re.sub(r'https\\S+', '', text)\n",
    "\n",
    "    # @<username>\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    # Non-alphabet character\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)\n",
    "\n",
    "    # #<word>\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "\n",
    "    # One character that doesn't belong to word or whitespace\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Attempt to remove linked pictures URLs\n",
    "    text = re.sub(r'pic\\w+', '', text)\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwords])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading language model\n",
    "model = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Lemmatiser\n",
    "def lemma(tokens):\n",
    "    doc = model(tokens)\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing emojis\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a text preprocessing function to apply to all rows\n",
    "def preprocess_text(text: str) -> list[str]:\n",
    "    text = regex_cleanse(text.lower())\n",
    "    text = remove_emoji(text)\n",
    "    text = lemma(text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a cleaned-preprocessed dataset\n",
    "cleaned = reviews.with_columns(pl.col('review').map_elements(preprocess_text, return_dtype = list[str]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>review</th><th>sentiment</th></tr><tr><td>list[str]</td><td>str</td></tr></thead><tbody><tr><td>[&quot;one&quot;, &quot;reviewer&quot;, … &quot;side&quot;]</td><td>&quot;positive&quot;</td></tr><tr><td>[&quot;wonderful&quot;, &quot;little&quot;, … &quot;do&quot;]</td><td>&quot;positive&quot;</td></tr><tr><td>[&quot;think&quot;, &quot;wonderful&quot;, … &quot;friend&quot;]</td><td>&quot;positive&quot;</td></tr><tr><td>[&quot;basically&quot;, &quot;there&quot;, … &quot;ignore&quot;]</td><td>&quot;negative&quot;</td></tr><tr><td>[&quot;petter&quot;, &quot;matteis&quot;, … &quot;work&quot;]</td><td>&quot;positive&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 2)\n",
       "┌─────────────────────────────────┬───────────┐\n",
       "│ review                          ┆ sentiment │\n",
       "│ ---                             ┆ ---       │\n",
       "│ list[str]                       ┆ str       │\n",
       "╞═════════════════════════════════╪═══════════╡\n",
       "│ [\"one\", \"reviewer\", … \"side\"]   ┆ positive  │\n",
       "│ [\"wonderful\", \"little\", … \"do\"… ┆ positive  │\n",
       "│ [\"think\", \"wonderful\", … \"frie… ┆ positive  │\n",
       "│ [\"basically\", \"there\", … \"igno… ┆ negative  │\n",
       "│ [\"petter\", \"matteis\", … \"work\"… ┆ positive  │\n",
       "└─────────────────────────────────┴───────────┘"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.write_ndjson(file = '../data/imdb_clean.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
