{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Notebook\n",
    "\n",
    "Notebook made for the RNN part of the assignment. Will contain all preprocessing and such, as well as implementation.\n",
    "\n",
    "This is a placeholder cell, code will follow later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries to work with\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sci\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import gensim as gns\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For the sake of Preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Word Embedding\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Version: 1.26.4\n",
      "Polars Version: 1.16.0\n",
      "MatPlotLib Version: 3.9.3\n",
      "Seaborn Version: 0.13.2\n",
      "PyTorch Version: 2.5.1+cpu\n",
      "NLTK Version: 3.9.1\n",
      "SpaCy Version: 3.8.2\n",
      "Gensim Version: 4.3.3\n",
      "SciPy Version: 1.13.1\n"
     ]
    }
   ],
   "source": [
    "# Display the libraries' versions used in this notebook\n",
    "version_list = {\"NumPy Version:\": np.__version__,\n",
    "                \"Polars Version:\": pl.__version__,\n",
    "                \"MatPlotLib Version:\": mpl.__version__,\n",
    "                \"Seaborn Version:\": sns.__version__,\n",
    "                \"PyTorch Version:\": torch.__version__,\n",
    "                \"NLTK Version:\": nltk.__version__,\n",
    "                \"SpaCy Version:\": spacy.__version__,\n",
    "                \"Gensim Version:\": gns.__version__,\n",
    "                \"SciPy Version:\": sci.__version__}\n",
    "\n",
    "for (k, v) in version_list.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining path to install NLTK libraries in\n",
    "NLTK_LIB_PATH = os.path.join(\"..\", \"venv_nlp\", \"Lib\", \"nltk_data\")\n",
    "\n",
    "# Defining download function\n",
    "def download_libs():\n",
    "    libraries = {\n",
    "        \"corpora\\\\stopwords\": \"stopwords\",\n",
    "        \"corpora\\\\wordnet\": \"wordnet\"\n",
    "    }\n",
    "\n",
    "    for resource, package in libraries.items():\n",
    "        try:\n",
    "            nltk.data.find(resource)\n",
    "            print(f\"{package.capitalize()} data exists.\")\n",
    "        except LookupError:\n",
    "            print(f\"Downloading {package}...\")\n",
    "\n",
    "            # Handle potential corrupted files\n",
    "            resource_path = os.path.join(NLTK_LIB_PATH, *resource.split('\\\\'))\n",
    "            if os.path.exists(resource_path):\n",
    "                print(f\"Removing corrupted file: {resource_path}\")\n",
    "                try:\n",
    "                    shutil.rmtree(resource_path) if os.path.isdir(resource_path) else os.remove(resource_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing corrupted file {resource_path}: {e}\")\n",
    "            # Attempt download again\n",
    "            nltk.download(package, download_dir=NLTK_LIB_PATH)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error checking {package}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using NLTK data directory: ..\\venv_nlp\\Lib\\nltk_data\n",
      "Stopwords data exists.\n",
      "Wordnet data exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs(NLTK_LIB_PATH, exist_ok=True)\n",
    "    print(f\"Using NLTK data directory: {NLTK_LIB_PATH}\")\n",
    "    download_libs()\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to create or write to directory '{NLTK_LIB_PATH}'\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
